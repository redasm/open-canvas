# 模型管理操作指南

## 概述

本文档基于 Open Canvas 项目重构后的模型配置系统，详细说明如何添加、删除和管理AI模型（如GPT、Claude、DeepSeek等）。重构后的系统大大简化了模型配置流程，从原来需要修改多个文件的复杂操作，简化为只需修改配置文件即可。

## 目录

1. [重构前后对比](#重构前后对比)
2. [快速添加新模型](#快速添加新模型)
3. [删除模型](#删除模型)
4. [模型配置详解](#模型配置详解)
5. [支持的模型提供商](#支持的模型提供商)
6. [环境变量配置](#环境变量配置)
7. [故障排除](#故障排除)
8. [最佳实践](#最佳实践)

## 重构前后对比

### 重构前（原始方式）

根据[Open Canvas官方仓库](https://github.com/langchain-ai/open-canvas)的说明，添加新模型需要：

1. **修改 `packages/shared/src/models.ts`** - 添加模型定义
2. **修改 `apps/agents/src/utils.ts`** - 更新 `getModelConfig` 函数
3. **安装新的依赖包** - 如 `@langchain/anthropic`
4. **设置环境变量** - API密钥等
5. **手动测试** - 验证所有功能是否正常

这种方式需要修改多个文件，容易出错且维护困难。

### 重构后（新方式）

现在只需要：

1. **修改 `config/models.json`** - 添加模型配置
2. **设置环境变量** - API密钥
3. **重启服务** - 自动加载新配置

## 快速添加新模型

### 步骤1：编辑配置文件

打开 `config/models.json` 文件，在相应位置添加新模型：

```json
{
  "providers": {
    "your-provider": {
      "name": "your-provider",
      "displayName": "Your Provider",
      "apiKey": "${YOUR_API_KEY}",
      "baseUrl": "https://api.your-provider.com/v1",
      "supportedFeatures": {
        "toolCalling": true,
        "streaming": true,
        "temperature": true,
        "maxTokens": 100000
      }
    }
  },
  "models": {
    "your-model": {
      "id": "your-model",
      "name": "your-model",
      "displayName": "Your Model",
      "provider": "your-provider",
      "capabilities": {
        "maxTokens": 8192,
        "temperatureRange": { "min": 0, "max": 1, "default": 0.5 },
        "supportsToolCalling": true,
        "supportsStreaming": true
      },
      "metadata": {
        "isNew": true,
        "category": "general",
        "description": "Your model description"
      }
    }
  }
}
```

### 步骤2：设置环境变量

在 `.env` 文件中添加API密钥：

```bash
# 在根目录 .env 文件中
YOUR_API_KEY=your_actual_api_key_here
```

### 步骤3：重启服务

```bash
# 重启LangGraph服务
cd apps/agents
yarn dev

# 重启前端服务
cd apps/web  
yarn dev
```

## 删除模型

### 方法1：从配置文件中删除

编辑 `config/models.json`，删除对应的模型配置：

```json
{
  "models": {
    // 删除这个模型配置
    // "old-model": { ... }
  }
}
```

### 方法2：使用管理接口

```typescript
import { ModelRegistry } from '@opencanvas/shared/config/model-registry';

// 删除特定模型
const registry = ModelRegistry.getInstance();
registry.removeModel('model-id');

// 删除整个提供商
registry.removeProvider('provider-name');
```

## 模型配置详解

### 提供商配置

```json
{
  "providers": {
    "provider-name": {
      "name": "provider-name",                    // 提供商标识符
      "displayName": "Provider Display Name",     // 显示名称
      "apiKey": "${API_KEY_ENV_VAR}",            // API密钥（环境变量）
      "baseUrl": "https://api.provider.com/v1",  // API基础URL（可选）
      "customHeaders": {                          // 自定义请求头（可选）
        "X-Custom-Header": "value"
      },
      "supportedFeatures": {
        "toolCalling": true,                      // 是否支持工具调用
        "streaming": true,                        // 是否支持流式响应
        "temperature": true,                      // 是否支持温度参数
        "maxTokens": 100000                       // 最大令牌数
      }
    }
  }
}
```

### 模型配置

```json
{
  "models": {
    "model-id": {
      "id": "model-id",                           // 模型唯一标识
      "name": "model-name",                       // 模型名称
      "displayName": "Model Display Name",        // 显示名称
      "provider": "provider-name",                // 所属提供商
      "capabilities": {
        "maxTokens": 8192,                        // 最大令牌数
        "temperatureRange": {                     // 温度参数范围
          "min": 0,
          "max": 1,
          "default": 0.5
        },
        "supportsToolCalling": true,              // 是否支持工具调用
        "supportsStreaming": true                 // 是否支持流式响应
      },
      "metadata": {
        "isNew": true,                            // 是否为新模型
        "category": "general",                    // 模型分类
        "description": "Model description"        // 模型描述
      }
    }
  }
}
```

## 支持的模型提供商

### 1. OpenAI

```json
{
  "providers": {
    "openai": {
      "name": "openai",
      "displayName": "OpenAI",
      "apiKey": "${OPENAI_API_KEY}",
      "supportedFeatures": {
        "toolCalling": true,
        "streaming": true,
        "temperature": true,
        "maxTokens": 100000
      }
    }
  },
  "models": {
    "gpt-4o": {
      "id": "gpt-4o",
      "name": "gpt-4o",
      "displayName": "GPT-4o",
      "provider": "openai",
      "capabilities": {
        "maxTokens": 16384,
        "temperatureRange": { "min": 0, "max": 1, "default": 0.5 },
        "supportsToolCalling": true,
        "supportsStreaming": true
      },
      "metadata": {
        "isNew": false,
        "category": "general",
        "description": "Latest GPT-4 model with improved performance"
      }
    }
  }
}
```

### 2. Anthropic

```json
{
  "providers": {
    "anthropic": {
      "name": "anthropic",
      "displayName": "Anthropic",
      "apiKey": "${ANTHROPIC_API_KEY}",
      "supportedFeatures": {
        "toolCalling": true,
        "streaming": true,
        "temperature": true,
        "maxTokens": 200000
      }
    }
  },
  "models": {
    "claude-3-5-sonnet-latest": {
      "id": "claude-3-5-sonnet-latest",
      "name": "claude-3-5-sonnet-latest",
      "displayName": "Claude 3.5 Sonnet",
      "provider": "anthropic",
      "capabilities": {
        "maxTokens": 8192,
        "temperatureRange": { "min": 0, "max": 1, "default": 0.5 },
        "supportsToolCalling": true,
        "supportsStreaming": true
      },
      "metadata": {
        "isNew": false,
        "category": "general",
        "description": "Anthropic's most capable model"
      }
    }
  }
}
```

### 3. DeepSeek (通过阿里云百炼)

```json
{
  "providers": {
    "fireworks": {
      "name": "fireworks",
      "displayName": "Fireworks AI",
      "apiKey": "${FIREWORKS_API_KEY}",
      "baseUrl": "https://dashscope.aliyuncs.com/compatible-mode/v1",
      "supportedFeatures": {
        "toolCalling": true,
        "streaming": true,
        "temperature": true,
        "maxTokens": 32000
      }
    }
  },
  "models": {
    "deepseek-v3": {
      "id": "deepseek-v3",
      "name": "deepseek-v3",
      "displayName": "DeepSeek V3",
      "provider": "fireworks",
      "capabilities": {
        "maxTokens": 8000,
        "temperatureRange": { "min": 0, "max": 1, "default": 0.5 },
        "supportsToolCalling": true,
        "supportsStreaming": true
      },
      "metadata": {
        "isNew": false,
        "category": "coding",
        "description": "Specialized coding model with strong reasoning capabilities"
      }
    }
  }
}
```

### 4. Google Gemini

```json
{
  "providers": {
    "google-genai": {
      "name": "google-genai",
      "displayName": "Google AI",
      "apiKey": "${GOOGLE_API_KEY}",
      "supportedFeatures": {
        "toolCalling": true,
        "streaming": true,
        "temperature": true,
        "maxTokens": 1000000
      }
    }
  },
  "models": {
    "gemini-2.0-flash": {
      "id": "gemini-2.0-flash",
      "name": "gemini-2.0-flash",
      "displayName": "Gemini 2.0 Flash",
      "provider": "google-genai",
      "capabilities": {
        "maxTokens": 1048576,
        "temperatureRange": { "min": 0, "max": 1, "default": 0.5 },
        "supportsToolCalling": true,
        "supportsStreaming": true
      },
      "metadata": {
        "isNew": false,
        "category": "general",
        "description": "Google's fastest multimodal model"
      }
    }
  }
}
```

### 5. 本地Ollama模型

```json
{
  "providers": {
    "ollama": {
      "name": "ollama",
      "displayName": "Ollama",
      "apiKey": "",
      "baseUrl": "http://host.docker.internal:11434",
      "supportedFeatures": {
        "toolCalling": false,
        "streaming": true,
        "temperature": true,
        "maxTokens": 2048
      }
    }
  },
  "models": {
    "ollama-llama3.3": {
      "id": "ollama-llama3.3",
      "name": "ollama-llama3.3",
      "displayName": "Llama 3.3 70B (local)",
      "provider": "ollama",
      "capabilities": {
        "maxTokens": 2048,
        "temperatureRange": { "min": 0, "max": 1, "default": 0.5 },
        "supportsToolCalling": false,
        "supportsStreaming": true
      },
      "metadata": {
        "isNew": false,
        "category": "local",
        "description": "Local Llama 3.3 model via Ollama"
      }
    }
  }
}
```

## 环境变量配置

### 必需的API密钥

在根目录的 `.env` 文件中配置：

```bash
# OpenAI
OPENAI_API_KEY=sk-your-openai-api-key

# Anthropic
ANTHROPIC_API_KEY=your-anthropic-api-key

# Google AI
GOOGLE_API_KEY=your-google-api-key

# Fireworks AI (用于DeepSeek等)
FIREWORKS_API_KEY=your-fireworks-api-key

# Groq
GROQ_API_KEY=your-groq-api-key

# Azure OpenAI (可选)
_AZURE_OPENAI_API_KEY=your-azure-api-key
_AZURE_OPENAI_API_INSTANCE_NAME=your-instance-name
_AZURE_OPENAI_API_DEPLOYMENT_NAME=your-deployment-name
_AZURE_OPENAI_API_VERSION=2024-08-01-preview
_AZURE_OPENAI_API_BASE_PATH=your-base-path

# Ollama (本地模型)
OLLAMA_API_URL=http://host.docker.internal:11434
```

### 前端环境变量

在 `apps/web/.env` 文件中配置：

```bash
# Supabase配置
NEXT_PUBLIC_SUPABASE_URL=your-supabase-url
NEXT_PUBLIC_SUPABASE_ANON_KEY=your-supabase-anon-key

# LangGraph API
LANGGRAPH_API_URL=http://localhost:54367

# 其他配置
NEXT_PUBLIC_OLLAMA_ENABLED=true
```

## 故障排除

### 1. 模型加载失败

**问题**：新添加的模型无法加载

**解决方案**：
```bash
# 1. 检查配置文件语法
cat config/models.json | jq .

# 2. 检查环境变量
echo $YOUR_API_KEY

# 3. 查看服务日志
cd apps/agents
yarn dev
```

### 2. API密钥错误

**问题**：`API key is invalid` 错误

**解决方案**：
```bash
# 1. 验证API密钥格式
# OpenAI: 以 sk- 开头
# Anthropic: 以 sk-ant- 开头
# Google: 以 AIza 开头

# 2. 检查环境变量名称
# 确保与配置文件中的变量名一致

# 3. 重启服务
yarn dev
```

### 3. 模型调用失败

**问题**：模型调用时出现错误

**解决方案**：
```typescript
// 检查模型配置
import { ModelRegistry } from '@opencanvas/shared/config/model-registry';

const registry = ModelRegistry.getInstance();
const model = registry.getModel('your-model-id');
console.log('Model config:', model);

// 检查提供商配置
const provider = registry.getProvider('your-provider');
console.log('Provider config:', provider);
```

### 4. 工具调用不支持

**问题**：模型不支持工具调用

**解决方案**：
```json
{
  "capabilities": {
    "supportsToolCalling": false  // 设置为false
  }
}
```

系统会自动回退到支持工具调用的模型。

## 最佳实践

### 1. 模型命名规范

```json
// 推荐的命名方式
{
  "id": "gpt-4o",                    // 简洁明了
  "name": "gpt-4o",                  // 与ID一致
  "displayName": "GPT-4o",           // 用户友好的显示名称
  "provider": "openai"               // 明确的提供商
}
```

### 2. 分类管理

```json
{
  "metadata": {
    "category": "general",           // 通用模型
    "category": "coding",            // 编程专用
    "category": "reasoning",         // 推理专用
    "category": "multimodal",        // 多模态
    "category": "local"              // 本地模型
  }
}
```

### 3. 能力配置

```json
{
  "capabilities": {
    "maxTokens": 8192,               // 根据模型实际能力设置
    "temperatureRange": {
      "min": 0,                      // 最小值
      "max": 1,                      // 最大值
      "default": 0.5                 // 默认值
    },
    "supportsToolCalling": true,     // 准确设置能力
    "supportsStreaming": true        // 准确设置能力
  }
}
```

### 4. 环境变量管理

```bash
# 使用描述性的变量名
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
GOOGLE_API_KEY=AIza...

# 不要使用通用名称
API_KEY=...  # 不推荐
KEY=...      # 不推荐
```

### 5. 配置文件管理

```bash
# 备份配置文件
cp config/models.json config/models.json.backup

# 使用版本控制
git add config/models.json
git commit -m "Add new model: your-model"
```

## 高级功能

### 1. 动态模型注册

```typescript
import { ModelRegistry } from '@opencanvas/shared/config/model-registry';

// 运行时注册新模型
const registry = ModelRegistry.getInstance();

registry.registerProvider({
  name: 'custom-provider',
  displayName: 'Custom Provider',
  apiKey: 'your-api-key',
  supportedFeatures: {
    toolCalling: true,
    streaming: true,
    temperature: true,
    maxTokens: 10000
  }
});

registry.registerModel({
  id: 'custom-model',
  name: 'custom-model',
  displayName: 'Custom Model',
  provider: 'custom-provider',
  capabilities: {
    maxTokens: 8000,
    temperatureRange: { min: 0, max: 1, default: 0.5 },
    supportsToolCalling: true,
    supportsStreaming: true
  },
  metadata: {
    isNew: true,
    category: 'general',
    description: 'Custom model description'
  }
});
```

### 2. 模型统计和监控

```typescript
// 获取模型统计信息
const stats = registry.getStats();
console.log('Total models:', stats.totalModels);
console.log('Models by provider:', stats.modelsByProvider);
console.log('Models by category:', stats.modelsByCategory);

// 搜索模型
const codingModels = registry.getModelsByCategory('coding');
const openaiModels = registry.getModelsByProvider('openai');
const searchResults = registry.searchModels('gpt');
```

### 3. 配置热重载

```typescript
import { ModelConfigLoader } from '@opencanvas/shared/config/model-loader';

const loader = ModelConfigLoader.getInstance();

// 检查配置是否已更改
if (loader.hasConfigChanged()) {
  await loader.reloadConfig();
  console.log('Model configuration reloaded');
}
```

## 总结

重构后的模型管理系统提供了：

1. **简化的配置流程** - 只需修改一个配置文件
2. **统一的配置接口** - 标准化的模型和提供商配置
3. **自动验证机制** - 确保配置的正确性
4. **动态加载支持** - 支持运行时配置更新
5. **完整的错误处理** - 清晰的错误信息和恢复建议
6. **丰富的监控功能** - 模型统计和搜索功能

通过遵循本文档的指导，您可以轻松地管理 Open Canvas 项目中的AI模型，大大简化了原来复杂的配置流程。

## 参考链接

- [Open Canvas 官方仓库](https://github.com/langchain-ai/open-canvas)
- [LangChain 文档](https://python.langchain.com/)
- [LangGraph 文档](https://langchain-ai.github.io/langgraph/)
